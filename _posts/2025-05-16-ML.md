---

title: 'RNN'
date: 2025-01-20
permalink: /posts/2025/05/ML/
tags:

- ML

---

## 机器学习基本概念

机器学习~=找一个（人类写不出来的）函数，而深度学习是利用**类神经网络**找函数

输入：向量/矩阵/序列（语音文字）-> 输出：数值（回归regress）/ 类别（分类）/ 图像文本

### 机器学习任务

- 如何教：
  
  - Supervised Learning：有数据集，有标签 data and label
    
  - Self-supervised Learning：利用unlable数据集学一些基本任务Pre-Train（Pre-trained Model又称为Foundation Model e.g.: Bert）
    
  - Generative Adversarial Network：不需要数据和标签成对
    
  - Reinforcement Learning：不知道最好的选择是啥
    
- 关注点：
  
  - Anomaly Dectection：异常检测
    
  - Explainable AI：可解释AI，讲为什么
    
  - Model Attack：模型攻击
    
  - Domain Adaptation：自适应
    
  - Network Compress：模型压缩
    
  - Life-long Learning
    
- 学习如何学习
  
  - Meta learning / Few-shot learning：机器自己从数据中发明一种算法，从少量数据学习。

### 深度学习概念推导

（1）步骤：

- 设计Model $y = b + wx_1$ $w$和$b$需要机器学习
  
- 从训练数据中设计Loss 损失是参数的函数$L(b,w)$ 估值和标签的差距
  
- Optimization最佳化：
  
  每次遮住只保留一个未知数（其实就是对损失函数求偏导）。
  
  ![](file://C:\Users\lenovo\AppData\Roaming\marktext\images\2025-05-14-22-01-40-image.png?msec=1749727536112)
  
  如果算的是负数，说明左大右小，增加$w$。学习率自己设置$η$，影响偏移的范围
  
  ![](file://C:\Users\lenovo\AppData\Roaming\marktext\images\2025-05-14-22-04-17-image.png?msec=1749727536097)
  
  当移动为0（不能再偏移了）停下来 -> 找到了局部最优。问题是：可能找不到全局最好
  

（2）经典线性模型太多简单，Model Bias -> 激活函数给与更多的非线性弹性特征

![](file://C:\Users\lenovo\AppData\Roaming\marktext\images\2025-05-14-22-19-39-image.png?msec=1749727536095)

计算展开可视化并转换成矩阵乘法：

![](file://C:\Users\lenovo\AppData\Roaming\marktext\images\2025-05-14-22-30-47-image.png?msec=1749727536095)

在机器学习中，将所有未知向量**平展并拼成**$θ$，那么损失函数就变成了计算$L(θ)$，此时Optimization阶段公式可以写成：

![](file://C:\Users\lenovo\AppData\Roaming\marktext\images\2025-05-14-22-37-01-image.png?msec=1749727536093)

参数太多，偏移通常不会自动停下来。同时对于数据的训练，也会划分多个batch。

![](file://C:\Users\lenovo\AppData\Roaming\marktext\images\2025-05-14-22-38-46-image.png?msec=1749727536095)

对于参数的计算还可以多做几次，就变成**神经网络**：

![](file://C:\Users\lenovo\AppData\Roaming\marktext\images\2025-05-14-22-42-24-image.png?msec=1749727536095)

也会出现Overfitting：数据集表现好，训练集表现不好
